TESTS = \

include $(JLM_ROOT)/tests/jlm/llvm/Makefile.sub
include $(JLM_ROOT)/tests/jlm/rvsdg/Makefile.sub
include $(JLM_ROOT)/tests/jlm/util/Makefile.sub
include $(JLM_ROOT)/tests/libjlm/Makefile.sub

TEST_SOURCES = \
	tests/test-operation.cpp \
	tests/test-registry.cpp \
	tests/test-runner.cpp \
	tests/test-types.cpp \
	tests/TestRvsdgs.cpp \
	$(patsubst %, tests/%.cpp, $(TESTS))

$(JLM_BUILD)/tests/test-runner: rvsdg-debug libjlm-debug
$(JLM_BUILD)/tests/test-runner: CXXFLAGS += $(CXXFLAGS_DEBUG)
$(JLM_BUILD)/tests/test-runner: CPPFLAGS += -I$(JLM_ROOT)/tests -I$(JLM_ROOT) -I$(JLM_ROOT)/libjlm/include -I$(shell $(LLVMCONFIG) --includedir)
$(JLM_BUILD)/tests/test-runner: LDFLAGS=-L$(JLM_BUILD) -ljlm $(shell $(LLVMCONFIG) --ldflags --libs --system-libs) -lllvm -lrvsdg -lutil
$(JLM_BUILD)/tests/test-runner: %: $(patsubst %.cpp, $(JLM_BUILD)/%.la, $(TEST_SOURCES)) $(JLM_BUILD)/librvsdg.a $(JLM_BUILD)/libjlm.a $(JLM_BUILD)/libllvm.a $(JLM_BUILD)/libutil.a
	mkdir -p ${dir $@}
	$(CXX) -o $@ $(filter %.la, $^) $(LDFLAGS)

$(patsubst %, %(JLM_BUILD)/tests/%.la, $(TESTS)): CPPFLAGS += -Itests -I$(shell $(LLVMCONFIG) --includedir)

TESTLOG = true

jlm-check: jlm-check-utests jlm-check-ctests

jlm-check-ctests: jlc-debug jlm-opt-debug
	@rm -rf $(JLM_ROOT)/ctests.log
	@FAILED_TESTS="" ; \
	for TEST in `ls $(JLM_ROOT)/tests/c-tests`; do \
		$(TESTLOG) -n "$$TEST: " ; if $(JLM_ROOT)/tests/test-jlc.sh ${JLM_ROOT} tests/c-tests/$$TEST >>$(JLM_ROOT)/ctests.log 2>&1 ; then $(TESTLOG) pass ; else $(TESTLOG) FAIL ; FAILED_TESTS="$$FAILED_TESTS $$TEST" ; fi ; \
	done ; \
	set -e ; \
	if [ "x$$FAILED_TESTS" != x ] ; then printf '\033[0;31m%s\033[0m%s\n' "Failed c-tests:" "$$FAILED_TESTS" ; exit 1 ; else printf '\033[0;32m%s\n\033[0m' "All c-tests passed" ; fi ; \

jlm-check-utests: $(JLM_BUILD)/tests/test-runner
	@rm -rf $(JLM_ROOT)/utests.log
	@FAILED_TESTS="" ; \
	for TEST in $(TESTS); do \
		$(TESTLOG) -n "$$TEST: " ; if $(JLM_BUILD)/tests/test-runner $$TEST >>$(JLM_ROOT)/utests.log 2>&1 ; then $(TESTLOG) pass ; else $(TESTLOG) FAIL ; FAILED_TESTS="$$FAILED_TESTS $$TEST" ; fi ; \
	done ; \
	set -e ; \
	if [ "x$$FAILED_TESTS" != x ] ; then printf '\033[0;31m%s\033[0m%s\n' "Failed u-tests:" "$$FAILED_TESTS" ; exit 1 ; else printf '\033[0;32m%s\n\033[0m' "All u-tests passed" ; fi ; \

jlm-valgrind-check: $(JLM_BUILD)/tests/test-runner
	@rm -rf $(JLM_ROOT)/check.log
	@FAILED_TESTS="" ; \
	for TEST in $(TESTS); do \
		$(TESTLOG) -n "$$TEST: " ; if valgrind --leak-check=full --error-exitcode=1 $(JLM_BUILD)/tests/test-runner $$TEST >>$(JLM_ROOT)/check.log 2>&1 ; then $(TESTLOG) pass ; else $(TESTLOG) FAIL ; FAILED_TESTS="$$UNEXPECTED_FAILED_TESTS $$TEST" ; fi ; \
	done ; \
	set -e ; \
	if [ "x$$FAILED_TESTS" != x ] ; then printf '\033[0;31m%s\033[0m%s\n' "Failed valgrind-tests:" "$$FAILED_TESTS" ; exit 1 ; else printf '\033[0;32m%s\n\033[0m' "All valgrind-tests passed" ; fi ; \

jlm-check-clean:
	rm -rf $(JLM_BUILD)/tests
	rm -f $(JLM_ROOT)/ctests.log
	rm -f $(JLM_ROOT)/utests.log
	rm -f $(JLM_ROOT)/check.log
